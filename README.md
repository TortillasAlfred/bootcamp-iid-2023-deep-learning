Introduction à l'apprentissage profond et PyTorch
=================================================

Présentation des bases de l'apprentissage profonds avec des exemples utilisant PyTorch et Poutyne. Les concepts suivants seront abordés:
 - Neurone
 - Couche pleinement connectée
 - Fonctions d'activation
 - Fonctions de perte
 - Régularisation
 - Entraînement et descente en gradient
 - Base des réseaux à convolutions

**Prérequis:** Connaissances de base en apprentissage automatique (présentation précédente)


Exécuter les notebooks
----------------------

Pour exécuter les notebooks avec un GPU (beaucoup plus rapide), vous pouvez utiliser Google Colab.

1. [Notebook avec le boston house-prices dataset (sklearn_dataset_training.ipynb)](https://colab.research.google.com/github/freud14/bootcamp-iid-2021-deep-learning/blob/master/sklearn_dataset_training.ipynb)
2. [Notebook avec MNIST (introduction_pytorch_poutyne.ipynb)](https://colab.research.google.com/github/freud14/bootcamp-iid-2021-deep-learning/blob/master/introduction_pytorch_poutyne.ipynb)
3. [Notebook avec du transfert d'apprentissage (transfer_learning.ipynb)](https://colab.research.google.com/github/freud14/bootcamp-iid-2021-deep-learning/blob/master/transfer_learning.ipynb)
